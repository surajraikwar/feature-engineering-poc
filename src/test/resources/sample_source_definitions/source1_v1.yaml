name: "customer_transactions"
description: "Raw customer transaction data from a local Parquet file."
version: "1.0"
type: "parquet" # Changed to parquet to indicate file type for DatabricksSparkSource
entity: "transaction"
location: "src/test/resources/data/dummy_transactions.parquet" # Points to local test file
fields:
  - name: "transaction_id"
    type: "string"
  - name: "customer_id"
    type: "string"
  - name: "transactionamount" # Matched to transformer default
    type: "double"
  - name: "transactiontimestamp" # Matched to transformer default
    type: "timestamp"
  - name: "creditdebitindicator" # Matched to transformer default
    type: "string"
  - name: "transactionstatus" # Matched to transformer default
    type: "string"
  - name: "transactionchannel" # Matched to transformer default
    type: "string"
  - name: "transactionmode" # Matched to transformer default
    type: "string"
  - name: "merchantcategory" # Matched to transformer default
    type: "string"
  - name: "country_code" # Kept from original
    type: "string"
config:
  # catalog, schema, table, query are removed as we are using 'location' and 'type: parquet'
  incremental: false
quality_checks:
  - type: "not_null"
    field: "transaction_id"
metadata:
  created_at: "2023-01-15T10:00:00Z"
  created_by: "test_user"
  tags: ["test_data", "parquet"]
